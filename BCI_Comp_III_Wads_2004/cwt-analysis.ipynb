{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:07.525452Z",
     "iopub.status.busy": "2024-04-24T08:25:07.524819Z",
     "iopub.status.idle": "2024-04-24T08:25:27.523241Z",
     "shell.execute_reply": "2024-04-24T08:25:27.522199Z",
     "shell.execute_reply.started": "2024-04-24T08:25:07.525423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io, signal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpywt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import io, signal\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:27.526605Z",
     "iopub.status.busy": "2024-04-24T08:25:27.525146Z",
     "iopub.status.idle": "2024-04-24T08:25:27.532224Z",
     "shell.execute_reply": "2024-04-24T08:25:27.530381Z",
     "shell.execute_reply.started": "2024-04-24T08:25:27.526565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ROOT = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:27.533817Z",
     "iopub.status.busy": "2024-04-24T08:25:27.533481Z",
     "iopub.status.idle": "2024-04-24T08:25:27.570955Z",
     "shell.execute_reply": "2024-04-24T08:25:27.569821Z",
     "shell.execute_reply.started": "2024-04-24T08:25:27.533790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 11, 13, 34, 51, 56, 60])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels=np.array([56,60,34,9,11,13,51]) # based on the paper by Tajmirriahi et al\n",
    "# [Po7,Po8,Fz,C3,Cz,C4,Pz]\n",
    "channels = np.sort(channels)\n",
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:27.573937Z",
     "iopub.status.busy": "2024-04-24T08:25:27.573597Z",
     "iopub.status.idle": "2024-04-24T08:25:27.583369Z",
     "shell.execute_reply": "2024-04-24T08:25:27.582267Z",
     "shell.execute_reply.started": "2024-04-24T08:25:27.573909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def BCI_DATASET():\n",
    "    dataset = {\n",
    "        'TRAIN':{\n",
    "            'A': io.loadmat('Subject_A_Train.mat'),\n",
    "            'B': io.loadmat('Subject_B_Train.mat')\n",
    "        },\n",
    "        'TEST': {\n",
    "            'A': io.loadmat('Subject_A_Test.mat'),\n",
    "            'B': io.loadmat('Subject_B_Test.mat')\n",
    "        }\n",
    "    }\n",
    "    return dataset\n",
    "\n",
    "def get_signal(dataset,subject,test=False):\n",
    "    data = {}\n",
    "    if test == False:\n",
    "        for i in dataset['TRAIN'][subject].keys():\n",
    "            data[i] = dataset['TRAIN'][subject][i]\n",
    "    \n",
    "    else:\n",
    "        for i in dataset['TEST'][subject].keys():\n",
    "            data[i] = dataset['TEST'][subject][i]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def visualize_data(data):\n",
    "    plt.plot(data)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:27.585634Z",
     "iopub.status.busy": "2024-04-24T08:25:27.584701Z",
     "iopub.status.idle": "2024-04-24T08:25:27.598227Z",
     "shell.execute_reply": "2024-04-24T08:25:27.597369Z",
     "shell.execute_reply.started": "2024-04-24T08:25:27.585605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Bandpass(input_signal,order,low,high,sampling_rate=240):\n",
    "    fn = sampling_rate*0.5\n",
    "    lb = low/fn\n",
    "    ub = high/fn\n",
    "    b,a = signal.butter(order/2,[lb,ub],'bandpass')\n",
    "    output = []\n",
    "    for i in range(64):\n",
    "        output_signal = signal.filtfilt(b,a,input_signal[:,i])\n",
    "        output.append(output_signal) \n",
    "    output = np.array(output)\n",
    "    output = np.moveaxis(output,-1,1)\n",
    "    return output\n",
    "\n",
    "def Subsample(input_signal,window,sampling_rate=240):\n",
    "    samples_per_window = sampling_rate*window//1000\n",
    "    samples = []\n",
    "    for i in range(0,7793,42):\n",
    "        samples.append(input_signal[:,i:i+samples_per_window])\n",
    "    \n",
    "    return samples[:-6]\n",
    "\n",
    "def Preprocess_Signals(input_data,test=False,sampling_rate=240,low=0.1,high=10,order=8,window=600):\n",
    "    preprocessed_signals = []\n",
    "    if test:\n",
    "        for i in range(100):\n",
    "            preprocessed_signals.append(Subsample(Bandpass(input_data[i],order,low,high),window))\n",
    "    else:\n",
    "        for i in range(85):\n",
    "            preprocessed_signals.append(Subsample(Bandpass(input_data[i],order,low,high),window))\n",
    "    \n",
    "    return preprocessed_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:27.599761Z",
     "iopub.status.busy": "2024-04-24T08:25:27.599459Z",
     "iopub.status.idle": "2024-04-24T08:25:37.154213Z",
     "shell.execute_reply": "2024-04-24T08:25:37.153214Z",
     "shell.execute_reply.started": "2024-04-24T08:25:27.599738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = BCI_DATASET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:37.155809Z",
     "iopub.status.busy": "2024-04-24T08:25:37.155430Z",
     "iopub.status.idle": "2024-04-24T08:25:37.160959Z",
     "shell.execute_reply": "2024-04-24T08:25:37.160154Z",
     "shell.execute_reply.started": "2024-04-24T08:25:37.155772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subj_A_train = get_signal(dataset,'A')\n",
    "Signal = subj_A_train['Signal']\n",
    "Stimulus_Code = subj_A_train['StimulusCode']\n",
    "Target_Char = np.array(list(subj_A_train['TargetChar'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:37.162448Z",
     "iopub.status.busy": "2024-04-24T08:25:37.162177Z",
     "iopub.status.idle": "2024-04-24T08:25:37.173890Z",
     "shell.execute_reply": "2024-04-24T08:25:37.173154Z",
     "shell.execute_reply.started": "2024-04-24T08:25:37.162425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subj_B_train = get_signal(dataset,'B')\n",
    "Signal_B = subj_B_train['Signal']\n",
    "Stimulus_Code_B = subj_B_train['StimulusCode']\n",
    "Target_Char_B = np.array(list(subj_B_train['TargetChar'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:37.175818Z",
     "iopub.status.busy": "2024-04-24T08:25:37.174979Z",
     "iopub.status.idle": "2024-04-24T08:25:37.185974Z",
     "shell.execute_reply": "2024-04-24T08:25:37.185112Z",
     "shell.execute_reply.started": "2024-04-24T08:25:37.175794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subj_A_test = get_signal(dataset,'A',test=True)\n",
    "Signal_A_test = subj_A_test['Signal']\n",
    "Stimulus_Code_A_test = subj_A_test['StimulusCode']\n",
    "Target_Char_A_test = np.array(list(['WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:37.189851Z",
     "iopub.status.busy": "2024-04-24T08:25:37.189309Z",
     "iopub.status.idle": "2024-04-24T08:25:53.562712Z",
     "shell.execute_reply": "2024-04-24T08:25:53.561373Z",
     "shell.execute_reply.started": "2024-04-24T08:25:37.189822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sigs_A = Preprocess_Signals(Signal,high=20,window=667)\n",
    "sign_B = Preprocess_Signals(Signal_B,high=20,window=667)\n",
    "sigs_A_test = Preprocess_Signals(Signal_A_test,high=20,window=667,test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:53.565190Z",
     "iopub.status.busy": "2024-04-24T08:25:53.564390Z",
     "iopub.status.idle": "2024-04-24T08:25:53.576006Z",
     "shell.execute_reply": "2024-04-24T08:25:53.574932Z",
     "shell.execute_reply.started": "2024-04-24T08:25:53.565143Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 'B', 'C', 'D', 'E', 'F'],\n",
       " ['G', 'H', 'I', 'J', 'K', 'L'],\n",
       " ['M', 'N', 'O', 'P', 'Q', 'R'],\n",
       " ['S', 'T', 'U', 'V', 'W', 'X'],\n",
       " ['Y', 'Z', '1', '2', '3', '4'],\n",
       " ['5', '6', '7', '8', '9', '_']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigm = [['A','B','C','D','E','F'],['G','H','I','J','K','L'],['M','N','O','P','Q','R'],['S','T','U','V','W','X'],['Y','Z','1','2','3','4'],['5','6','7','8','9','_']]\n",
    "paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:53.578333Z",
     "iopub.status.busy": "2024-04-24T08:25:53.577706Z",
     "iopub.status.idle": "2024-04-24T08:25:53.616653Z",
     "shell.execute_reply": "2024-04-24T08:25:53.615010Z",
     "shell.execute_reply.started": "2024-04-24T08:25:53.578302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def check_row(item,row_number):\n",
    "    if item in paradigm[row_number]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def is_p300(stim_code,char):\n",
    "    # As each row and column was flashed for 100ms in the experiment, the number of samples = 24 (240*(100/1000))\n",
    "    # We will find out the row for the corresponding stimulus code\n",
    "    row = stim_code\n",
    "    if stim_code > 6:\n",
    "        row = stim_code-6\n",
    "    return check_row(char,row-1)\n",
    "\n",
    "def extract_flashes(Stim_Code):\n",
    "    buffer = []\n",
    "    flashes = []\n",
    "    for i in range(0,7793,42):\n",
    "        buffer.append(int(Stim_Code[i]))\n",
    "    for i in range(len(buffer)):\n",
    "        if buffer[i] > 0:\n",
    "            flashes.append(buffer[i])\n",
    "        \n",
    "    return flashes\n",
    "\n",
    "def get_labels(Stim_Code,Target_Char):\n",
    "    labels = []\n",
    "    sample_labels = []\n",
    "    for i,char in zip(Stim_Code,Target_Char):\n",
    "        flashes = extract_flashes(i)\n",
    "        for j in flashes:\n",
    "            sample_labels.append(is_p300(j,char))\n",
    "        labels.append(sample_labels)\n",
    "        sample_labels = []\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:53.627524Z",
     "iopub.status.busy": "2024-04-24T08:25:53.623728Z",
     "iopub.status.idle": "2024-04-24T08:25:53.732506Z",
     "shell.execute_reply": "2024-04-24T08:25:53.731857Z",
     "shell.execute_reply.started": "2024-04-24T08:25:53.627462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels = get_labels(Stimulus_Code,Target_Char)\n",
    "labels_B = get_labels(Stimulus_Code_B,Target_Char_B)\n",
    "labels_A_test = get_labels(Stimulus_Code_A_test,Target_Char_A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:53.733862Z",
     "iopub.status.busy": "2024-04-24T08:25:53.733635Z",
     "iopub.status.idle": "2024-04-24T08:25:53.740224Z",
     "shell.execute_reply": "2024-04-24T08:25:53.739199Z",
     "shell.execute_reply.started": "2024-04-24T08:25:53.733842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_p300_signals(labels):\n",
    "    buffer = []\n",
    "    p300 = []\n",
    "    buffer_2 = []\n",
    "    non_p300 = []\n",
    "    for char in range(85):\n",
    "        for flash in range(180):\n",
    "            if labels[char][flash]==1:\n",
    "                buffer.append(flash)\n",
    "            else:\n",
    "                buffer_2.append(flash)\n",
    "        non_p300.append(buffer_2)\n",
    "        p300.append(buffer)\n",
    "        buffer = []\n",
    "        buffer_2 = []\n",
    "                \n",
    "    return [p300,non_p300]\n",
    "def clone_signals(signals,times):\n",
    "    print(np.array(signals).shape)\n",
    "    cloned_signals = signals*(times+1)\n",
    "    return np.array(cloned_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:53.741835Z",
     "iopub.status.busy": "2024-04-24T08:25:53.741335Z",
     "iopub.status.idle": "2024-04-24T08:25:54.093921Z",
     "shell.execute_reply": "2024-04-24T08:25:54.092952Z",
     "shell.execute_reply.started": "2024-04-24T08:25:53.741804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550\n",
      "(2550, 64, 160)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12750, 64, 160)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_A = extract_p300_signals(labels)\n",
    "p300_A = []\n",
    "for i in range(85):\n",
    "    for j in range(len(subj_A[0][i])):\n",
    "        p300_A.append(sigs_A[i][j])\n",
    "print(len(p300_A))\n",
    "clones = clone_signals(p300_A,4)\n",
    "clones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.095325Z",
     "iopub.status.busy": "2024-04-24T08:25:54.095037Z",
     "iopub.status.idle": "2024-04-24T08:25:54.159961Z",
     "shell.execute_reply": "2024-04-24T08:25:54.159160Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.095300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "p300_A = np.array(p300_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.161761Z",
     "iopub.status.busy": "2024-04-24T08:25:54.161216Z",
     "iopub.status.idle": "2024-04-24T08:25:54.167467Z",
     "shell.execute_reply": "2024-04-24T08:25:54.166544Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.161723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 64, 160)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p300_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.169308Z",
     "iopub.status.busy": "2024-04-24T08:25:54.168885Z",
     "iopub.status.idle": "2024-04-24T08:25:54.463429Z",
     "shell.execute_reply": "2024-04-24T08:25:54.462532Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.169277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12750, 64, 160)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np300_A = []\n",
    "for i in range(85):\n",
    "    for j in range(len(subj_A[1][i])):\n",
    "        np300_A.append(sigs_A[i][j])\n",
    "\n",
    "np300_A = np.array(np300_A)\n",
    "np300_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.464880Z",
     "iopub.status.busy": "2024-04-24T08:25:54.464566Z",
     "iopub.status.idle": "2024-04-24T08:25:54.475035Z",
     "shell.execute_reply": "2024-04-24T08:25:54.474103Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.464854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "p300_balanced = p300_A[:300]\n",
    "np300_balanced = np300_A[:300]\n",
    "p300_balanced = p300_balanced[:,channels]\n",
    "np300_balanced = np300_balanced[:,channels]\n",
    "p300_balanced = p300_balanced.reshape((10,210,160))\n",
    "np300_balanced = np300_balanced.reshape((10,210,160))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.476475Z",
     "iopub.status.busy": "2024-04-24T08:25:54.476182Z",
     "iopub.status.idle": "2024-04-24T08:25:54.482784Z",
     "shell.execute_reply": "2024-04-24T08:25:54.481840Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.476452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of balanced p300 signals is (10, 210, 160), and non p300 signals is (10, 210, 160)\n"
     ]
    }
   ],
   "source": [
    "# proof of data balancing (done as done by Tajmirriahi et al)\n",
    "print(f'The size of balanced p300 signals is {p300_balanced.shape}, and non p300 signals is {np300_balanced.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.484481Z",
     "iopub.status.busy": "2024-04-24T08:25:54.484213Z",
     "iopub.status.idle": "2024-04-24T08:25:54.496876Z",
     "shell.execute_reply": "2024-04-24T08:25:54.496050Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.484458Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 64, 160)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np300_A = np300_A[:2550]\n",
    "np300_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.498114Z",
     "iopub.status.busy": "2024-04-24T08:25:54.497836Z",
     "iopub.status.idle": "2024-04-24T08:25:54.507965Z",
     "shell.execute_reply": "2024-04-24T08:25:54.507236Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.498092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_p300_A = p300_A[:2500]\n",
    "test_p300_A = p300_A[2500:2550]\n",
    "train_np300_A = np300_A[:2500]\n",
    "test_np300_A = np300_A[2500:2550]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.509413Z",
     "iopub.status.busy": "2024-04-24T08:25:54.509064Z",
     "iopub.status.idle": "2024-04-24T08:25:54.534730Z",
     "shell.execute_reply": "2024-04-24T08:25:54.533876Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.509356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_p300_A = train_p300_A.reshape((2500*64,160))\n",
    "train_np300_A = train_np300_A.reshape((2500*64,160))\n",
    "test_p300_A = test_p300_A.reshape((50*64,160))\n",
    "test_np300_A = test_np300_A.reshape((50*64,160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.536345Z",
     "iopub.status.busy": "2024-04-24T08:25:54.536090Z",
     "iopub.status.idle": "2024-04-24T08:25:54.552178Z",
     "shell.execute_reply": "2024-04-24T08:25:54.551274Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.536324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wavelets = pywt.wavelist(kind='continuous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.554005Z",
     "iopub.status.busy": "2024-04-24T08:25:54.553394Z",
     "iopub.status.idle": "2024-04-24T08:25:54.568150Z",
     "shell.execute_reply": "2024-04-24T08:25:54.567214Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.553974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cgau1',\n",
       " 'cgau2',\n",
       " 'cgau3',\n",
       " 'cgau4',\n",
       " 'cgau5',\n",
       " 'cgau6',\n",
       " 'cgau7',\n",
       " 'cgau8',\n",
       " 'cmor',\n",
       " 'fbsp',\n",
       " 'gaus1',\n",
       " 'gaus2',\n",
       " 'gaus3',\n",
       " 'gaus4',\n",
       " 'gaus5',\n",
       " 'gaus6',\n",
       " 'gaus7',\n",
       " 'gaus8',\n",
       " 'mexh',\n",
       " 'morl',\n",
       " 'shan']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:25:54.572700Z",
     "iopub.status.busy": "2024-04-24T08:25:54.572376Z",
     "iopub.status.idle": "2024-04-24T08:30:01.852510Z",
     "shell.execute_reply": "2024-04-24T08:30:01.851241Z",
     "shell.execute_reply.started": "2024-04-24T08:25:54.572678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt  # Ensure pywt (PyWavelets) is installed\n",
    "\n",
    "wavelets = ['morl', 'fbsp1-1.5-1.0', 'shan1.0-1.5', 'mexh']\n",
    "wavelet_names = ['morlet', 'fbsp', 'shannon', 'mexican_hat']\n",
    "\n",
    "# Define new save path\n",
    "save_path = r\"C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\"\n",
    "\n",
    "for wavelet, name in zip(wavelets, wavelet_names):\n",
    "    counter_p300 = 0\n",
    "    counter_np300 = 0\n",
    "    widths = np.arange(1, 100)\n",
    "    time = np.linspace(0, 0.667, num=160)\n",
    "\n",
    "    # Change directory creation to new path\n",
    "    os.mkdir(os.path.join(save_path, name))\n",
    "    os.mkdir(os.path.join(save_path, name, 'p300'))\n",
    "    os.mkdir(os.path.join(save_path, name, 'np300'))\n",
    "\n",
    "    for j in range(10):\n",
    "        for i in p300_balanced[j]:\n",
    "            cwtmatr, freqs = pywt.cwt(i, widths, wavelet)\n",
    "            if name == 'shannon' or name == 'fbsp':\n",
    "                plt.imsave(os.path.join(save_path, name, 'p300', str(counter_p300) + '.jpg'), np.imag(cwtmatr))\n",
    "            else:\n",
    "                plt.imsave(os.path.join(save_path, name, 'p300', str(counter_p300) + '.jpg'), cwtmatr)\n",
    "            counter_p300 += 1\n",
    "\n",
    "        for i in np300_balanced[j]:\n",
    "            cwtmatr, freqs = pywt.cwt(i, widths, wavelet)\n",
    "            if name == 'shannon' or name == 'fbsp':\n",
    "                plt.imsave(os.path.join(save_path, name, 'np300', str(counter_np300) + '.jpg'), np.imag(cwtmatr))\n",
    "            else:\n",
    "                plt.imsave(os.path.join(save_path, name, 'np300', str(counter_np300) + '.jpg'), cwtmatr)\n",
    "            plt.axis('off')\n",
    "            counter_np300 += 1\n",
    "        print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:30:08.894772Z",
     "iopub.status.busy": "2024-04-24T08:30:08.894403Z",
     "iopub.status.idle": "2024-04-24T08:30:08.901845Z",
     "shell.execute_reply": "2024-04-24T08:30:08.900980Z",
     "shell.execute_reply.started": "2024-04-24T08:30:08.894744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(r\"C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\\morlet\\p300\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:22:57.942913Z",
     "iopub.status.busy": "2024-04-24T08:22:57.942114Z",
     "iopub.status.idle": "2024-04-24T08:22:57.947205Z",
     "shell.execute_reply": "2024-04-24T08:22:57.946326Z",
     "shell.execute_reply.started": "2024-04-24T08:22:57.942879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# os.rmdir('/kaggle/working/morlet/p300')\n",
    "# os.rmdir('/kaggle/working/morlet/np300')\n",
    "# os.rmdir('/kaggle/working/morlet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vgg16 = tf.keras.applications.VGG16(include_top=False,input_shape=(256,256,3),weights= 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:30:15.286936Z",
     "iopub.status.busy": "2024-04-24T08:30:15.286148Z",
     "iopub.status.idle": "2024-04-24T08:30:15.295642Z",
     "shell.execute_reply": "2024-04-24T08:30:15.294744Z",
     "shell.execute_reply.started": "2024-04-24T08:30:15.286906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # building the model \n",
    "# def conv_block(input_value,alpha=0.2,dropout=False,pool_size=2,stride_size=2):\n",
    "#     block = tf.keras.models.Sequential(\n",
    "#     [\n",
    "#         tf.keras.layers.Conv2D(32,5),\n",
    "#         tf.keras.layers.BatchNormalization(),\n",
    "#         tf.keras.layers.LeakyReLU(negative_slope=alpha),\n",
    "#         tf.keras.layers.MaxPooling2D(pool_size,stride_size),\n",
    "#     ]\n",
    "#     )\n",
    "#     x = block(input_value)\n",
    "#     if dropout:\n",
    "#         x = tf.keras.layers.Dropout(0.3)(x)\n",
    "#     return tf.keras.Model(input_value,x)\n",
    "\n",
    "# def Model(input_value):\n",
    "#     block1 = conv_block(input_value)\n",
    "#     x = block1(input_value)\n",
    "#     block2 = conv_block(x)\n",
    "#     x = block2(x)\n",
    "#     block3 = conv_block(x,alpha=0,dropout=True,pool_size=4,stride_size=6)\n",
    "#     x = block3(x)\n",
    "#     fully_connected = tf.keras.models.Sequential(\n",
    "#     [\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(64),\n",
    "#         tf.keras.layers.Dense(32,'tanh'),\n",
    "#         tf.keras.layers.Dense(1,'sigmoid')\n",
    "#     ]\n",
    "#     )\n",
    "#     x = fully_connected(x)\n",
    "#     return tf.keras.Model(input_value,x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T08:19:12.001592Z",
     "iopub.status.idle": "2024-04-24T08:19:12.002054Z",
     "shell.execute_reply": "2024-04-24T08:19:12.001838Z",
     "shell.execute_reply.started": "2024-04-24T08:19:12.001819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_vgg16():\n",
    "    vgg16 = tf.keras.applications.VGG16(include_top=True,input_shape=(256,256,3),weights=None,classes=1,classifier_activation='sigmoid')\n",
    "    \n",
    "    return vgg16\n",
    "\n",
    "def train_vgg(train_dataset,valid_dataset):\n",
    "    vgg16 = build_vgg16()\n",
    "    vgg16.compile(tf.keras.optimizers.Adadelta(0.001),loss='binary_crossentropy',metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    h1 = vgg16.fit(train_dataset,batch_size=8,epochs=50,validation_data=valid_dataset)\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:30:56.470569Z",
     "iopub.status.busy": "2024-04-24T08:30:56.469969Z",
     "iopub.status.idle": "2024-04-24T08:30:56.476660Z",
     "shell.execute_reply": "2024-04-24T08:30:56.475705Z",
     "shell.execute_reply.started": "2024-04-24T08:30:56.470537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def build_CNN():\n",
    "#     model = Model(tf.keras.Input((256,256,3)))\n",
    "#     return model\n",
    "\n",
    "# def train_CNN(train_dataset,valid_dataset):\n",
    "#     CNN = build_CNN()\n",
    "#     CNN.compile(tf.keras.optimizers.Adadelta(0.001),loss='binary_crossentropy',metrics=['acc',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "#     h1 = CNN.fit(train_dataset,batch_size=8,epochs=300,validation_data=valid_dataset)\n",
    "#     return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\\.gitattributes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m directory \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(base_path)[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m      5\u001b[0m     dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, directory)\n\u001b[1;32m----> 7\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     valid_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     12\u001b[0m         dir_path, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     15\u001b[0m     h\u001b[38;5;241m.\u001b[39mappend(train_vgg(train_dataset, valid_dataset))\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:223\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 223\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:530\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    529\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    532\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\\.gitattributes"
     ]
    }
   ],
   "source": [
    "# h = []\n",
    "# base_path = r\"C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\"\n",
    "\n",
    "# for directory in os.listdir(base_path)[1:]:\n",
    "#     dir_path = os.path.join(base_path, directory)\n",
    "\n",
    "#     train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "#         dir_path, batch_size=8, shuffle=True, validation_split=0.2, seed=42, subset='training'\n",
    "#     )\n",
    "\n",
    "#     valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "#         dir_path, batch_size=8, shuffle=True, validation_split=0.2, seed=42, subset='validation'\n",
    "#     )\n",
    "\n",
    "#     h.append(train_vgg(train_dataset, valid_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T08:19:12.004621Z",
     "iopub.status.idle": "2024-04-24T08:19:12.004948Z",
     "shell.execute_reply": "2024-04-24T08:19:12.004800Z",
     "shell.execute_reply.started": "2024-04-24T08:19:12.004786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(r\"C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\\mexican_hat\\np300\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:30:22.715604Z",
     "iopub.status.busy": "2024-04-24T08:30:22.715231Z",
     "iopub.status.idle": "2024-04-24T08:30:22.722940Z",
     "shell.execute_reply": "2024-04-24T08:30:22.722064Z",
     "shell.execute_reply.started": "2024-04-24T08:30:22.715576Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\.git',\n",
       " 'C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\.gitattributes',\n",
       " 'C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\BCI_Comp_III_Wads_2004',\n",
       " 'C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\fbsp',\n",
       " 'C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\mexican_hat',\n",
       " 'C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\morlet',\n",
       " 'C:\\\\Users\\\\hrush\\\\OneDrive\\\\Documents\\\\Bci work\\\\BCI-3-work\\\\shannon']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = []\n",
    "base_path = r\"C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\"\n",
    "\n",
    "for i in os.listdir(base_path):\n",
    "    if i == '.virtual_documents':  # Skip this directory\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(base_path, i)\n",
    "        directories.append(path)\n",
    "\n",
    "directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T08:31:01.801796Z",
     "iopub.status.busy": "2024-04-24T08:31:01.801086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# h = []\n",
    "# base_path = r\"C:\\Users\\hrush\\OneDrive\\Documents\\Bci work\\BCI-3-work\"\n",
    "\n",
    "# # Iterate over directories in the base path and filter out non-image directories\n",
    "# for directory in os.listdir(base_path):\n",
    "#     dir_path = os.path.join(base_path, directory)\n",
    "    \n",
    "#     # Check if the directory contains images (or is not hidden like .git)\n",
    "#     if os.path.isdir(dir_path) and not directory.startswith('.') and any(f.endswith(('.png', '.jpg', '.jpeg', '.bmp')) for f in os.listdir(dir_path)):\n",
    "        \n",
    "#         # Load the datasets\n",
    "#         train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "#             dir_path, \n",
    "#             batch_size=32, \n",
    "#             shuffle=True, \n",
    "#             validation_split=0.2, \n",
    "#             seed=42, \n",
    "#             subset='training'\n",
    "#         )\n",
    "\n",
    "#         valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "#             dir_path, \n",
    "#             batch_size=32, \n",
    "#             shuffle=True, \n",
    "#             validation_split=0.2, \n",
    "#             seed=42, \n",
    "#             subset='validation'\n",
    "#         )\n",
    "        \n",
    "#         # Add the result to the list\n",
    "#         h.append(train_vgg(train_dataset, valid_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4200 files belonging to 2 classes.\n",
      "Found 4200 files belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m  6/525\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:37\u001b[0m 4s/step - binary_accuracy: 0.3031 - loss: 0.8137 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 25\u001b[0m\n\u001b[0;32m     16\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     17\u001b[0m     dir_path,\n\u001b[0;32m     18\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Now you can pass the datasets to the train_vgg function\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m, in \u001b[0;36mtrain_vgg\u001b[1;34m(train_dataset, valid_dataset)\u001b[0m\n\u001b[0;32m      7\u001b[0m vgg16\u001b[38;5;241m.\u001b[39mcompile(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdadelta(\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(), tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mPrecision(), tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mRecall()])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[43mvgg16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Extracting the accuracy values from the history object\u001b[39;00m\n\u001b[0;32m     13\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m h1\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# List of accuracy values for each epoch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\hrush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example directory paths where your images are stored\n",
    "train_dir = 'path_to_train_directory'\n",
    "valid_dir = 'path_to_valid_directory'\n",
    "\n",
    "# Load the train and validation datasets\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dir_path,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=8,\n",
    "    label_mode='binary',  # Use 'binary' if you have binary classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dir_path,\n",
    "    image_size=(256, 256),\n",
    "    batch_size=8,\n",
    "    label_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Now you can pass the datasets to the train_vgg function\n",
    "h1 = train_vgg(train_dataset, valid_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4685625,
     "sourceId": 7984243,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
